output_folder: ./results        # Main output folder. All the outputs (log, plots, models) will be saved to this folder
sub_folders:                    # Subfolder names for model, plot, and log                  
  model : mdl
  plot  : plot
  log   : log
  
file_suffix: test               # str, all the leaf output file name will contain this suffix
n_epoch: 20000                  # Total number of epochs
save_loss_every: 100           # Save logs per [such] epochs
save_plot_model_every: 1000           # Save model and plots per [such] epochs, n_epoch / save_plot_every better not exceed 500
stdout : 1                      # 0: print to screen, 1: print to log file
batch_seed : 0                       # random seed for mini-batch; used only when batch_size is not 'full'


problem:                        # Parameters for problem
  name  : Chemistry 
  train_file_path : ./problems/chemistry_train.txt
  test_file_path : ./problems/chemistry_test.txt
  regs:                           # regularization multipliers of different losses composing objective function
    pde     : 1.0e-2
    boundary: 1.0e-2
    fitting : 1
  n_constrs: 10                    # number of constraints ---
  constraint_type : other       # other (mass-balance constraint)
  batch_size: 0.2               # str full or float(0,1) represents the percentage of n_train_obj_samples_per_group['pde'] use for mini-batch
  nn_name       : FCN           # neural network name. This should be a class in nn_architecture.py
  nn_input      : 5             # x, t, u_zero
  nn_output     : 4
  nn_parameters:                # The keys can be different for different neural network
    n_hidden: 64
    n_layers: 3
  t_max: 10                      # null or int value associated to time range limit.
  t_discretization: 64         # null or int value used for discretization of time range
  fitting_sample_percentage : 0.2
  n_initial_conditions : 1000     # int. number of initial condition generated
  n_test_initial_conditions: 1
  
optimizer:
  name : sqp                  # adam or sgd or sqp 
  lr    : 1.0e-3
  mu    : 1.0e-7
  beta2 : 0.999
  pretrain: null              # null; or dict with keys: epoch_start and file_suffix
  alpha_type: 'p_adam'         # 'adam', or 'p_adam' 
  beta1 : 0.9
